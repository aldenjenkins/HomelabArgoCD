apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: kubeletstats
spec:
  serviceAccount: otel-collector
  mode: daemonset
  # Update all pods in parallel instead of one-by-one rolling update
  daemonSetUpdateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 100%
  image: otel/opentelemetry-collector-contrib:0.143.1
  imagePullPolicy: IfNotPresent
  resources:
    limits:
      memory: 512Mi
    requests:
      cpu: 10m
      memory: 64Mi
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  config:
    # # Define connectors which connect two pipelines, acting as both exporter and receiver.
    # # see: https://opentelemetry.io/docs/collector/components/connector/
    # # and: https://opentelemetry.io/docs/collector/configuration/#connectors
    # connectors:
    #   forward/keda: {}

    # Define exporters to data stores.
    # See https://opentelemetry.io/docs/collector/configuration/#exporters
    # Also see https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor#recommended-processors
    exporters:
      debug:
        verbosity: detailed
      otlphttp/prometheus:
        endpoint: http://prometheus-k8s.prometheus.svc.cluster.local:9090/api/v1/otlp
        tls:
          insecure: true
        retry_on_failure:
          enabled: false
        sending_queue:
          num_consumers: 50
        timeout: 10s
      prometheusremotewrite:
        # endpoint: http://prometheus-k8s.prometheus.svc.cluster.local:9090/api/v1/write
        endpoint: http://thanos-receive.thanos.svc.cluster.local:19291/api/v1/receive
        add_metric_suffixes: false
        tls:
          insecure: true
        retry_on_failure:
          enabled: true
        remote_write_queue:
          enabled: true
          num_consumers: 50
          queue_size: 1000
        timeout: 10s
    extensions:
      pprof: {}
    # Define processors to process received data.
    # See https://opentelemetry.io/docs/collector/configuration/#processors
    processors:
      batch:
        send_batch_max_size: 2000
        send_batch_size: 1000
        timeout: 10s
      # Clean up empty label values from target_info (Thanos Receive rejects empty labels)
      transform/cleanup_empty_labels:
        metric_statements:
          - context: datapoint
            statements:
              - delete_key(attributes, "server_port") where attributes["server_port"] == ""
          - context: resource
            statements:
              - delete_key(attributes, "server.port") where attributes["server.port"] == ""
      # filter/toggled_metrics:
      #   metrics:
      #     metric:
      #       - IsMatch(name, "k8s\\.volume\\..+") and (resource.attributes["homelab.observability.detailed_volume_metrics"] == nil or resource.attributes["homelab.observability.detailed_volume_metrics"] != "true")
      groupbyattrs:
        keys:
          - k8s.pod.name
          - k8s.namespace.name

      k8sattributes:
        auth_type: serviceAccount
        extract:
          annotations:
            - from: pod
              key: observability.home.alden.ai/detailed_volume_metrics_enabled
              tag_name: homelab.observability.detailed_volume_metrics
          labels:
            - from: pod
              key: app.homelab/environment
              tag_name: homelab.environment
            - from: pod
              key: app.homelab/huid
              tag_name: homelab.huid
            - from: pod
              key: app.homelab/owner
              tag_name: homelab.owner
            - from: pod
              key: app.homelab/service
              tag_name: homelab.service
            - from: pod
              key: app.homelab/argo-rollout-name
              tag_name: argo.rollout.name
          metadata:
            - k8s.deployment.name
            - k8s.statefulset.name
            - k8s.daemonset.name
            - k8s.cronjob.name
            - k8s.job.name
        filter:
          node_from_env_var: K8S_NODE_NAME
        passthrough: false
        pod_association:
          - sources:
              - from: resource_attribute
                name: k8s.pod.name
              - from: resource_attribute
                name: k8s.namespace.name
        wait_for_metadata: true
        wait_for_metadata_timeout: 30s
      memory_limiter:
        check_interval: 1s
        limit_percentage: 90
        spike_limit_percentage: 10
      metricstransform/add_standard_labels:
        transforms:
          - action: update
            include: .+
            match_type: regexp
            operations:
              # - action: add_label
              #   new_label: aws_account
              #   new_value: homelab-live
              # - action: add_label
              #   new_label: homelab_source
              #   new_value: aws_account:homelab-live
              - action: add_label
                new_label: homelab_otel_source
                new_value: kubeletstats-collector
      metricstransform/rename_cpu_metrics:
        transforms:
          - action: update
            include: container.cpu.usage
            new_name: container.cpu.utilization
          - action: update
            include: k8s.pod.cpu.usage
            new_name: k8s.pod.cpu.utilization
          - action: update
            include: k8s.node.cpu.usage
            new_name: k8s.node.cpu.utilization
      resource/set_known_attributes:
        attributes:
          - action: upsert
            key: k8s.cluster.name
            value: homelab-live
      resourcedetection/homelab:
        detectors: [env, system]
        timeout: 5s
        override: false
        attributes:
          - k8s.node.name
      transform/cleanup:
        metric_statements:
          - context: resource
            statements:
              - delete_key(attributes, "host.name")
              - delete_matching_keys(attributes, "^k8s.+?uid")
      transform/label_metrics:
        metric_statements:
          - context: datapoint
            statements:
              # Nil checks prevent empty labels (Thanos Receive rejects them)
              - set(attributes["instance"], resource.attributes["k8s.pod.name"]) where resource.attributes["k8s.pod.name"] != nil
              - set(attributes["instance"], "${env:K8S_NODE_NAME}") where resource.attributes["k8s.pod.name"] == nil
              - set(attributes["container.image.name"], resource.attributes["container.image.name"]) where resource.attributes["container.image.name"] != nil
              - set(attributes["container.image.tag"], resource.attributes["container.image.tag"]) where resource.attributes["container.image.tag"] != nil
              - set(attributes["k8s.deployment.name"], resource.attributes["k8s.deployment.name"]) where resource.attributes["k8s.deployment.name"] != nil
              - set(attributes["k8s.daemonset.name"], resource.attributes["k8s.daemonset.name"]) where resource.attributes["k8s.daemonset.name"] != nil
              - set(attributes["k8s.statefulset.name"], resource.attributes["k8s.statefulset.name"]) where resource.attributes["k8s.statefulset.name"] != nil
              - set(attributes["k8s.cronjob.name"], resource.attributes["k8s.cronjob.name"]) where resource.attributes["k8s.cronjob.name"] != nil
              - set(attributes["argo.rollout.name"], resource.attributes["argo.rollout.name"]) where resource.attributes["argo.rollout.name"] != nil
              - set(attributes["service.name"], resource.attributes["k8s.deployment.name"]) where resource.attributes["k8s.deployment.name"] != nil
              - set(attributes["service.name"], resource.attributes["k8s.statefulset.name"]) where resource.attributes["k8s.statefulset.name"] != nil
              - set(attributes["service.name"], resource.attributes["k8s.cronjob.name"]) where resource.attributes["k8s.cronjob.name"] != nil
              - set(attributes["service.name"], resource.attributes["k8s.daemonset.name"]) where resource.attributes["k8s.daemonset.name"] != nil
              - set(attributes["service.name"], resource.attributes["argo.rollout.name"]) where resource.attributes["argo.rollout.name"] != nil
              - set(attributes["k8s.job.name"], resource.attributes["k8s.job.name"]) where resource.attributes["k8s.job.name"] != nil
              - set(attributes["k8s.namespace.name"], resource.attributes["k8s.namespace.name"]) where resource.attributes["k8s.namespace.name"] != nil
              - set(attributes["k8s.node.name"], "${env:K8S_NODE_NAME}")
              - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"]) where resource.attributes["k8s.pod.name"] != nil
              - set(attributes["k8s.cluster.name"], resource.attributes["k8s.cluster.name"]) where resource.attributes["k8s.cluster.name"] != nil
              - set(attributes["k8s.container.name"], resource.attributes["k8s.container.name"]) where resource.attributes["k8s.container.name"] != nil
              - set(attributes["host.image.id"], resource.attributes["host.image.id"]) where resource.attributes["host.image.id"] != nil
              - set(attributes["homelab_source"], "cloud_system_metrics") where resource.attributes["k8s.namespace.name"] == "homelab-system"
              - set(attributes["homelab_source"], "cloud_system_metrics") where resource.attributes["k8s.namespace.name"] == "kube-system"
              - set(attributes["cloud.availability_zone"], resource.attributes["cloud.availability_zone"]) where resource.attributes["cloud.availability_zone"] != nil and IsMatch(metric.name, "k8s.node.+")
              - set(attributes["cloud.region"], resource.attributes["cloud.region"]) where resource.attributes["cloud.region"] != nil and IsMatch(metric.name, "k8s.node.+")
              - set(attributes["host.type"], resource.attributes["host.type"]) where resource.attributes["host.type"] != nil and IsMatch(metric.name, "k8s.node.+")
              - set(attributes["homelab.service"], resource.attributes["homelab.service"]) where resource.attributes["homelab.service"] != nil
              - set(attributes["homelab.owner"], resource.attributes["homelab.owner"]) where resource.attributes["homelab.owner"] != nil
              - set(attributes["homelab.huid"], resource.attributes["homelab.huid"]) where resource.attributes["homelab.huid"] != nil
              - set(attributes["homelab.environment"], resource.attributes["homelab.environment"]) where resource.attributes["homelab.environment"] != nil
              - set(attributes["homelab.tenant"], "prometheus") where resource.attributes["k8s.namespace.name"] != nil and resource.attributes["k8s.namespace.name"] != "homelab-system" and resource.attributes["k8s.namespace.name"] != "kube-system"
              - set(attributes["homelab.tenant"], "core-tech") where resource.attributes["k8s.namespace.name"] == "homelab-system" or resource.attributes["k8s.namespace.name"] == "kube-system"
      transform/set_match_resource_attributes:
        metric_statements:
          - context: datapoint
            statements:
              - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"]) where resource.attributes["k8s.pod.name"] != nil
              - set(attributes["k8s.namespace.name"], resource.attributes["k8s.namespace.name"]) where resource.attributes["k8s.namespace.name"] != nil
              - set(attributes["k8s.volume.name"], resource.attributes["k8s.volume.name"]) where resource.attributes["k8s.volume.name"] != nil
              - set(attributes["k8s.volume.type"], resource.attributes["k8s.volume.type"]) where resource.attributes["k8s.volume.type"] != nil
    receivers:
      # kubeletstats:
      #   auth_type: serviceAccount
      #   collection_interval: 20s
      #   endpoint: https://${env:K8S_NODE_NAME}:10250
      #   insecure_skip_verify: true
      #   metric_groups:
      #     - node
      #     - pod
      #     - container
      #     - volume
      #   metrics:
      #     k8s.pod.uptime:
      #       enabled: true
      # prometheus/kubelet-raw:
      #   config:
      #     scrape_configs:
      #       - job_name: 'kubelet'  # <-- Sets the job label required by your rule
      #         bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
      #         kubernetes_sd_configs:
      #           - role: node
      #         relabel_configs:
      #           - replacement: kubernetes.default.svc:443
      #             target_label: __address__
      #           - regex: (.+)
      #             replacement: /api/v1/nodes/$$1/proxy/metrics/cadvisor
      #             source_labels:
      #               - __meta_kubernetes_node_name
      #             target_label: __metrics_path__
      #           - target_label: metrics_path
      #             replacement: /metrics/cadvisor  # <-- Explicitly set for your PromQL rule
      #           - source_labels: [__meta_kubernetes_node_name]
      #             target_label: instance
      #         scheme: https
      #         tls_config:
      #           ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
      #           insecure_skip_verify: true
      prometheus/kubelet-and-node-exporter:
        config:
          scrape_configs:
            # ---------- /metrics ----------
            - job_name: 'kubelet'
              honor_labels: true
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              scheme: https
              tls_config:
                insecure_skip_verify: true
              metrics_path: /metrics
              scrape_interval: 30s

              static_configs:
                - targets: ['${env:K8S_NODE_NAME}:10250']

              # Ensure "job" label matches ServiceMonitor jobLabel behavior
              relabel_configs:
                - action: replace
                  target_label: job
                  replacement: kubelet
                - action: replace
                  target_label: cluster
                  replacement: homelab-live
                - action: replace
                  source_labels: [__metrics_path__]
                  target_label: metrics_path

              # metricRelabelings from ServiceMonitor endpoint #1
              metric_relabel_configs:
                - action: drop
                  source_labels: [__name__]
                  regex: kubelet_(pod_worker_latency_microseconds|pod_start_latency_microseconds|cgroup_manager_latency_microseconds|pod_worker_start_latency_microseconds|pleg_relist_latency_microseconds|pleg_relist_interval_microseconds|runtime_operations|runtime_operations_latency_microseconds|runtime_operations_errors|eviction_stats_age_microseconds|device_plugin_registration_count|device_plugin_alloc_latency_microseconds|network_plugin_operations_latency_microseconds)
                - action: drop
                  source_labels: [__name__]
                  regex: scheduler_(e2e_scheduling_latency_microseconds|scheduling_algorithm_predicate_evaluation|scheduling_algorithm_priority_evaluation|scheduling_algorithm_preemption_evaluation|scheduling_algorithm_latency_microseconds|binding_latency_microseconds|scheduling_latency_seconds)
                - action: drop
                  source_labels: [__name__]
                  regex: apiserver_(request_count|request_latencies|request_latencies_summary|dropped_requests|storage_data_key_generation_latencies_microseconds|storage_transformation_failures_total|storage_transformation_latencies_microseconds|proxy_tunnel_sync_latency_secs|longrunning_gauge|registered_watchers|storage_db_total_size_in_bytes|flowcontrol_request_concurrency_limit|flowcontrol_request_concurrency_in_use)
                - action: drop
                  source_labels: [__name__]
                  regex: kubelet_docker_(operations|operations_latency_microseconds|operations_errors|operations_timeout)
                - action: drop
                  source_labels: [__name__]
                  regex: reflector_(items_per_list|items_per_watch|list_duration_seconds|lists_total|short_watches_total|watch_duration_seconds|watches_total)
                - action: drop
                  source_labels: [__name__]
                  regex: etcd_(helper_cache_hit_count|helper_cache_miss_count|helper_cache_entry_count|object_counts|request_cache_get_latencies_summary|request_cache_add_latencies_summary|request_latencies_summary)
                - action: drop
                  source_labels: [__name__]
                  regex: transformation_(transformation_latencies_microseconds|failures_total)
                - action: drop
                  source_labels: [__name__]
                  regex: (admission_quota_controller_adds|admission_quota_controller_depth|admission_quota_controller_longest_running_processor_microseconds|admission_quota_controller_queue_latency|admission_quota_controller_unfinished_work_seconds|admission_quota_controller_work_duration|APIServiceOpenAPIAggregationControllerQueue1_adds|APIServiceOpenAPIAggregationControllerQueue1_depth|APIServiceOpenAPIAggregationControllerQueue1_longest_running_processor_microseconds|APIServiceOpenAPIAggregationControllerQueue1_queue_latency|APIServiceOpenAPIAggregationControllerQueue1_retries|APIServiceOpenAPIAggregationControllerQueue1_unfinished_work_seconds|APIServiceOpenAPIAggregationControllerQueue1_work_duration|APIServiceRegistrationController_adds|APIServiceRegistrationController_depth|APIServiceRegistrationController_longest_running_processor_microseconds|APIServiceRegistrationController_queue_latency|APIServiceRegistrationController_retries|APIServiceRegistrationController_unfinished_work_seconds|APIServiceRegistrationController_work_duration|autoregister_adds|autoregister_depth|autoregister_longest_running_processor_microseconds|autoregister_queue_latency|autoregister_retries|autoregister_unfinished_work_seconds|autoregister_work_duration|AvailableConditionController_adds|AvailableConditionController_depth|AvailableConditionController_longest_running_processor_microseconds|AvailableConditionController_queue_latency|AvailableConditionController_retries|AvailableConditionController_unfinished_work_seconds|AvailableConditionController_work_duration|crd_autoregistration_controller_adds|crd_autoregistration_controller_depth|crd_autoregistration_controller_longest_running_processor_microseconds|crd_autoregistration_controller_queue_latency|crd_autoregistration_controller_retries|crd_autoregistration_controller_unfinished_work_seconds|crd_autoregistration_controller_work_duration|crdEstablishing_adds|crdEstablishing_depth|crdEstablishing_longest_running_processor_microseconds|crdEstablishing_queue_latency|crdEstablishing_retries|crdEstablishing_unfinished_work_seconds|crdEstablishing_work_duration|crd_finalizer_adds|crd_finalizer_depth|crd_finalizer_longest_running_processor_microseconds|crd_finalizer_queue_latency|crd_finalizer_retries|crd_finalizer_unfinished_work_seconds|crd_finalizer_work_duration|crd_naming_condition_controller_adds|crd_naming_condition_controller_depth|crd_naming_condition_controller_longest_running_processor_microseconds|crd_naming_condition_controller_queue_latency|crd_naming_condition_controller_retries|crd_naming_condition_controller_unfinished_work_seconds|crd_naming_condition_controller_work_duration|crd_openapi_controller_adds|crd_openapi_controller_depth|crd_openapi_controller_longest_running_processor_microseconds|crd_openapi_controller_queue_latency|crd_openapi_controller_retries|crd_openapi_controller_unfinished_work_seconds|crd_openapi_controller_work_duration|DiscoveryController_adds|DiscoveryController_depth|DiscoveryController_longest_running_processor_microseconds|DiscoveryController_queue_latency|DiscoveryController_retries|DiscoveryController_unfinished_work_seconds|DiscoveryController_work_duration|kubeproxy_sync_proxy_rules_latency_microseconds|non_structural_schema_condition_controller_adds|non_structural_schema_condition_controller_depth|non_structural_schema_condition_controller_longest_running_processor_microseconds|non_structural_schema_condition_controller_queue_latency|non_structural_schema_condition_controller_retries|non_structural_schema_condition_controller_unfinished_work_seconds|non_structural_schema_condition_controller_work_duration|rest_client_request_latency_seconds|storage_operation_errors_total|storage_operation_status_count)

            # ---------- /metrics/cadvisor ----------
            - job_name: 'kubelet-cadvisor'
              honor_labels: true
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              scheme: https
              tls_config:
                insecure_skip_verify: true
              metrics_path: /metrics/cadvisor
              scrape_interval: 30s
              honor_timestamps: false

              static_configs:
                - targets: ['${env:K8S_NODE_NAME}:10250']

              relabel_configs:
                - action: replace
                  target_label: job
                  replacement: kubelet
                - action: replace
                  target_label: cluster
                  replacement: homelab-live
                - action: replace
                  source_labels: [__metrics_path__]
                  target_label: metrics_path

              metric_relabel_configs:
                - action: drop
                  source_labels: [__name__]
                  regex: container_(network_tcp_usage_total|network_udp_usage_total|tasks_state|cpu_load_average_10s)
                - action: drop
                  source_labels: [__name__, pod, namespace]
                  regex: (container_spec_.*|container_file_descriptors|container_sockets|container_threads_max|container_threads|container_start_time_seconds|container_last_seen);;
                - action: drop
                  source_labels: [__name__, container]
                  regex: (container_blkio_device_usage_total);.+

            # ---------- /metrics/probes ----------
            - job_name: 'kubelet-probes'
              honor_labels: true
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              scheme: https
              tls_config:
                insecure_skip_verify: true
              metrics_path: /metrics/probes
              scrape_interval: 30s

              static_configs:
                - targets: ['${env:K8S_NODE_NAME}:10250']

              relabel_configs:
                - action: replace
                  target_label: job
                  replacement: kubelet
                - action: replace
                  target_label: cluster
                  replacement: homelab-live
                - action: replace
                  source_labels: [__metrics_path__]
                  target_label: metrics_path

            # ---------- /metrics/slis ----------
            - job_name: 'kubelet-slis'
              honor_labels: true
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              scheme: https
              tls_config:
                insecure_skip_verify: true
              metrics_path: /metrics/slis
              scrape_interval: 5s

              static_configs:
                - targets: ['${env:K8S_NODE_NAME}:10250']

              relabel_configs:
                - action: replace
                  target_label: job
                  replacement: kubelet
                - action: replace
                  target_label: cluster
                  replacement: homelab-live
                - action: replace
                  source_labels: [__metrics_path__]
                  target_label: metrics_path

              metric_relabel_configs:
                - action: drop
                  source_labels: [__name__]
                  regex: process_start_time_seconds

            # ========= node-exporter (replaces ServiceMonitor/node-exporter) =========
            - job_name: node-exporter
              kubernetes_sd_configs:
                - role: pod

              relabel_configs:
                # Match ServiceMonitor .spec.selector.matchLabels
                - action: keep
                  regex: exporter
                  source_labels:
                    - __meta_kubernetes_pod_label_app_kubernetes_io_component
                - action: keep
                  regex: node-exporter
                  source_labels:
                    - __meta_kubernetes_pod_label_app_kubernetes_io_name
                - action: keep
                  regex: kube-prometheus
                  source_labels:
                    - __meta_kubernetes_pod_label_app_kubernetes_io_part_of
                - action: keep
                  regex: node-exporter
                  source_labels:
                    - __meta_kubernetes_namespace

                # **Only scrape the node-exporter pod on *this* node**
                - action: keep
                  source_labels:
                    - __meta_kubernetes_pod_node_name
                  regex: ${env:K8S_NODE_NAME}

                # Only scrape the "https" port on the node-exporter pod
                - action: keep
                  regex: https
                  source_labels:
                    - __meta_kubernetes_pod_container_port_name

                # Use HTTPS, like the ServiceMonitor
                - action: replace
                  target_label: __scheme__
                  replacement: https

                # Build podIP:port as the target address
                - action: replace
                  source_labels:
                    - __meta_kubernetes_pod_ip
                    - __meta_kubernetes_pod_container_port_number
                  regex: (.*);(.*)
                  replacement: $1:$2
                  target_label: __address__

                # Set cluster label (ServiceMonitor relabelings[0])
                - action: replace
                  target_label: cluster
                  replacement: homelab-live

                # Set instance label from node name (ServiceMonitor relabelings[1])
                - action: replace
                  source_labels:
                    - __meta_kubernetes_pod_node_name
                  target_label: instance

                # Match jobLabel: app.kubernetes.io/name â†’ job="node-exporter"
                - action: replace
                  target_label: job
                  replacement: node-exporter

              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              scheme: https
              tls_config:
                insecure_skip_verify: true
              scrape_interval: 15s

    service:
      # extensions:
      #   - pprof
      pipelines:
        metrics:
          exporters:
            # - otlphttp/prometheus
            - prometheusremotewrite
            # - debug
          processors:
            - memory_limiter
            ############
            # - metricstransform/add_standard_labels
            # - resource/set_known_attributes
            # - resourcedetection/homelab
            ########
            - batch
            - transform/cleanup_empty_labels
            ############
            # - transform/set_match_resource_attributes
            # - groupbyattrs
            # - k8sattributes
            ###########
            # - filter/toggled_metrics
            # #######################################
            # - transform/label_metrics
            # - transform/cleanup
            # ############################
            # - metricstransform/rename_cpu_metrics
          receivers:
            # - kubeletstats
            - prometheus/kubelet-and-node-exporter
      telemetry:
        logs:
          encoding: json
          # level: debug
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: 0.0.0.0
                    port: 8888
                    without_units: true
        resource:
          homelab_otel_component: kubeletstats-collector

