apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otlp
spec:
  autoscaler:
    maxReplicas: 3
    minReplicas: 1
    targetCPUUtilization: 75
    targetMemoryUtilization: 90
  mode: deployment
  resources:
    limits:
      cpu: "2"
      memory: 1536Mi
    requests:
      cpu: "1"
      memory: 512Mi
  serviceAccount: otel-collector
  image: otel/opentelemetry-collector-contrib:0.139.0
  config:
    # Define connectors which connect two pipelines, acting as both exporter and receiver.
    # see: https://opentelemetry.io/docs/collector/components/connector/
    # and: https://opentelemetry.io/docs/collector/configuration/#connectors
    # connectors:
    #   forward/keda: {}

    # Define exporters to data stores.
    # See https://opentelemetry.io/docs/collector/configuration/#exporters
    # Also see https://github.com/open-telemetry/opentelemetry-collector/tree/main/processor#recommended-processors
    exporters:

      # Unused ATM.
      debug:
        verbosity: detailed

      # Exporter for sending Prometheus data to Mimir.
      prometheusremotewrite:
        # Don't add suffixes to the metrics. We've already renamed the `traces.spanmetrics.calls` metric to
        # `traces.spanmetrics.calls.total`, and we don't want to add the `_milliseconds` suffix to the
        # `traces.spanmetrics.latency` metric.
        add_metric_suffixes: false
        # Send to the locally running Mimir service.
        endpoint: http://prometheus-k8s.prometheus.svc.cluster.local:9090/api/v1/write
        # TLS is not enabled for the instance.
        tls:
          insecure: true

      # prometheusremotewrite/keda:
      #   endpoint: http://prometheus-k8s.prometheus.svc.cluster.local:9090/api/v1/write
      #   max_batch_size_bytes: 3000000
      #   remote_write_queue:
      #     enabled: true
      #     num_consumers: 5
      #     queue_size: 1000
      #   timeout: 1s
      #

    extensions:
      pprof: {}
      health_check:
        endpoint: 0.0.0.0:13133
        path: /healthz


    # Define processors to process received data.
    # See https://opentelemetry.io/docs/collector/configuration/#processors
    processors:
      # Use the in-built `batch` processor to batch up data before writing it for export.
      batch:
        timeout: 1s
        send_batch_size: 1000
        send_batch_max_size: 2000
      filter/keda_metrics:
        metrics:
          include:
            match_type: regexp
            metric_names:
              - keda_.+
              - http.server.duration
              - http.server.request.duration

      # cardinality:
      #   aggregation_keys:
      #     - service.name
      #   circuit-breaker_adjustment_interval: 5m
      #   circuit-breaker_adjustment_weight: 0.5
      #   circuit-breaker_mode: disabled
      #   ignore_keys_in_calculation:
      #     - instance
      #     - k8s.job.name
      #     - k8s.pod.ip
      #     - k8s.pod.name
      #     - k8s.pod.uid
      #     - k8s_pod_name
      #     - k8s.node.name
      #     - net.host.name
      #     - node
      #     - nodeName
      #     - pod
      #     - podName
      #     - server.address
      #     - service.instance.id
      #   max_cardinality_per_metric_aggregation: 5000

      # For k8sattributes to properly decorate pods, metrics must be grouped under the same resource attributes.
      # This step should be applied AFTER batching.
      groupbyattrs:
        keys:
          - k8s.pod.name
          - k8s.namespace.name

      # resourcedetection/homelab:
      #   detectors: [env, system]
      #   timeout: 5s
      #   override: false
      #   attributes:
      #     - k8s.cluster.name
      #     - k8s.node.name

      # Most of these below processors were taken from this: https://github.com/softwaremill/meerkat/blob/3d5d8590fac865d4d672210475019e8b7c330ae0/otel/jvm-collector.yaml#L87-L102
      k8sattributes:
        auth_type: serviceAccount
        passthrough: false
        wait_for_metadata: true
        wait_for_metadata_timeout: 30s
        # filter:
          # node_from_env_var: KUBE_NODE_NAME
        pod_association:
          #     # This rule associates all resources containing the 'k8s.pod.ip' attribute with the matching pods.
          #     # If this attribute is not present in the resource, this rule will not be able to find the matching pod.
          #     - from: resource_attribute
          #       name: k8s.pod.ip
          # - sources:
          #     # This rule associates all resources containing the 'k8s.pod.uid' attribute with the matching pods.
          #     # If this attribute is not present in the resource, this rule will not be able to find the matching pod.
          #     - from: resource_attribute
          #       name: k8s.pod.uid
          - sources:
              # - from: resource_attribute
                # name: k8s.node.name
              - from: resource_attribute
                name: k8s.pod.name
              - from: resource_attribute
                name: k8s.namespace.name
          # - sources:
          #     # This rule will use the IP from the incoming connection from which the resource is received,
          #     # and find the matching pod, based on the 'pod.status.podIP' of the observed pods
          #     - from: connection
        extract:
          # The attributes provided in 'metadata' will be added to associated resources
          metadata:  # extracted from the pod
            - k8s.cronjob.name
            - k8s.daemonset.name
            - k8s.deployment.name
            - k8s.job.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.pod.start_time
            - k8s.statefulset.name
          #labels:
          # # This label extraction rule takes the value 'app.kubernetes.io/component' label and maps it to the 'app.label.component' attribute which will be added to the associated resources
          # - tag_name: app.label.component
          #   key: app.kubernetes.io/component
          #   from: pod
          labels:
            - tag_name: app.label.component
              key: app.kubernetes.io/component
              from: pod
            - tag_name: app.label.name
              key: app.kubernetes.io/name
              from: pod
            - tag_name: app  # extracts value of label from pods with key `app` and inserts it as a tag with key `app`
              key: app
              from: pod
            - from: pod
              key: app.homelab/environment
              tag_name: homelab.environment
            - from: pod
              key: app.homelab/huid
              tag_name: homelab.huid
            - from: pod
              key: app.homelab/owner
              tag_name: homelab.owner
            - from: pod
              key: app.homelab/service
              tag_name: homelab.service
            - from: pod
              key: app.homelab/argo-rollout-name
              tag_name: argo.rollout.name
      memory_limiter:
        check_interval: 1s
        limit_percentage: 90
        spike_limit_percentage: 10
      metricstransform/add_standard_labels:
        transforms:
          - action: update
            include: .+
            match_type: regexp
            operations:
              - action: add_label
                new_label: aws_account
                new_value: homelab-live
              - action: add_label
                new_label: homelab_source
                new_value: aws_account:homelab-live
              - action: add_label
                new_label: homelab_otel_source
                new_value: otlp-collector
      resource/drop_attributes:
        attributes:
          - action: delete
            key: process.command_args # drop this long attribute generated by otel auto-instrumentation, which makes target_info too large to write
      # required to send metrics to chronosphere, but might be able to remove for prometheus
      resource/service-instance:
        attributes:
          - action: insert
            from_attribute: k8s.pod.name
            key: service.instance.id
          - action: insert
            from_attribute: k8s.node.name
            key: service.instance.id
          - action: insert
            from_attribute: host.name
            key: service.instance.id
          - action: insert
            value: unknown
            key: service.instance.id
      resource/set_known_attributes:
        attributes:
          - action: upsert
            key: k8s.cluster.name
            value: homelab-live
      transform/label_metrics:
        metric_statements:
          - context: datapoint
            statements:
              - set(attributes["instance"], resource.attributes["k8s.pod.name"]) where
                resource.attributes["k8s.pod.name"] != nil
              - set(attributes["instance"], resource.attributes["k8s.node.name"]) where
                resource.attributes["k8s.pod.name"] != nil
              - set(attributes["service.name"], resource.attributes["service.name"]) where
                resource.attributes["service.name"] != nil
              - set(attributes["container.image.name"], resource.attributes["container.image.name"])
              - set(attributes["container.image.tag"], resource.attributes["container.image.tag"])
              - set(attributes["k8s.deployment.name"], resource.attributes["k8s.deployment.name"])
              - set(attributes["k8s.daemonset.name"], resource.attributes["k8s.daemonset.name"])
              - set(attributes["k8s.statefulset.name"], resource.attributes["k8s.statefulset.name"])
              - set(attributes["k8s.cronjob.name"], resource.attributes["k8s.cronjob.name"])
              - set(attributes["k8s.job.name"], resource.attributes["k8s.job.name"])
              - set(attributes["k8s.namespace.name"], resource.attributes["k8s.namespace.name"])
              - set(attributes["k8s.node.name"], resource.attributes["k8s.node.name"])
              - set(attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])
              - set(attributes["k8s.cluster.name"], resource.attributes["k8s.cluster.name"])
              - set(attributes["k8s.container.name"], resource.attributes["k8s.container.name"])
              - set(attributes["namespaceName"], resource.attributes["k8s.namespace.name"])
              - set(attributes["nodeName"], resource.attributes["k8s.node.name"])
              - set(attributes["podName"], resource.attributes["k8s.pod.name"])
              - set(attributes["clusterName"], resource.attributes["k8s.cluster.name"])
              - set(attributes["homelab.service"], resource.attributes["homelab.service"]) where resource.attributes["homelab.service"] != nil
              - set(attributes["homelab.owner"], resource.attributes["homelab.owner"]) where resource.attributes["homelab.owner"] != nil
              - set(attributes["homelab.huid"], resource.attributes["homelab.huid"]) where resource.attributes["homelab.huid"] != nil
              - set(attributes["homelab.env"], resource.attributes["homelab.env"]) where resource.attributes["homelab.env"] != nil
              - set(attributes["homelab.environment"], resource.attributes["homelab.environment"]) where resource.attributes["homelab.environment"] != nil
              - set(attributes["homelab.version"], resource.attributes["homelab.version"]) where resource.attributes["homelab.version"] != nil
              - set(attributes["homelab.tenant"], "prometheus-k8s")

      transform/set_match_resource_attributes:
        metric_statements:
          - context: datapoint
            statements:
              - set(resource.attributes["k8s.pod.name"], resource.attributes["k8s.pod.name"])
              - set(resource.attributes["k8s.namespace.name"], resource.attributes["k8s.namespace.name"])

    # Define the protocols to receive data for.
    # See https://opentelemetry.io/docs/collector/configuration/#receivers
    receivers:
      # Configure receiving OTLP data via gRPC on port 4317 and HTTP on port 4318.
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
            keepalive:
              server_parameters:
                max_connection_age: 5s
                max_connection_age_grace: 5s
          http:
            endpoint: 0.0.0.0:4318
            max_request_body_size: 41943040

    # Define the full service graph for the OpenTelemetry collector.
    service:
      extensions:
        - health_check
      pipelines:
        metrics:
          receivers: 
          - otlp
          processors: 
          - memory_limiter
          - resource/set_known_attributes
          - resource/drop_attributes
          - metricstransform/add_standard_labels
          - resource/service-instance
          - batch 
          - transform/set_match_resource_attributes
          - groupbyattrs
          - k8sattributes
          # - resourcedetection/homelab
          - transform/label_metrics
          exporters: 
          # - forward/keda
          - prometheusremotewrite
        # metrics/keda:
        #   exporters:
        #     - prometheusremotewrite/keda
        #   processors:
        #     - filter/keda_metrics
        #     - batch
        #   receivers:
        #     - forward/keda
      telemetry:
        logs:
          encoding: json
          level: info
        # Push collector internal metrics to Prometheus
        metrics:
          readers:
            - pull:
                exporter:
                  prometheus:
                    host: 0.0.0.0
                    port: 8888
                    without_units: true
        resource:
          homelab_otel_component: otlp-collector
